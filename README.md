# tfashion2.0 - A model to identify fashion-related words (hybrid approach)
- Remark:
  - BERT is generally better suited for sentence-level tasks rather than word-level classification.
  - A balanced dataset of fashion and non-fashion corpora is important
- hybrid approach: using BERT to classify the fashion relevance of larger segments (phrases or sentences) instead of individual words, followed by RAKE (keyword extraction technique) and a softer matching to filter out non-fashion words.

## Steps
1. Expand fashion corpus [topics_filtered.csv](https://github.com/dengxw66/Multimodal_MKT/blob/diandian_devlop/topics_filtered.csv) and prepare nonfashion-corpus (chinese wikipedia)
2. Fine-tune BERT on the fashion corpus [topics_filtered.csv](https://github.com/dengxw66/Multimodal_MKT/blob/diandian_devlop/topics_filtered.csv) for phrase-level or sentence-level classification.  
3. Classify the fashion-relatedness of each post in cleaned_post_text using BERT.  
4. Extract fashion-related keywords using RAKE from fashion-classified text.  
5. Apply softer matching only to fashion-related keywords.   
- Therefore, we filter out non-fashion words in the posts using the fashion corpus (the dictionary).

## Summary
- BERT is used at the sentence level to classify whether a text is fashion-related.
- RAKE is applied to extract keywords from the fashion-related sentences.
- Soft matching is applied to extracted fashion keywords.
  
## model performance
![Screenshot 2024-09-06 at 11 02 21](https://github.com/user-attachments/assets/871a5c75-6dac-4070-a981-8dd6f9e214e0)
- Number of fashion-related posts: 15277
- Number of non-fashion-related posts: 345
- Examples of 'non-fashion posts':
![Screenshot 2024-09-06 at 11 10 57](https://github.com/user-attachments/assets/f4f43533-3473-4693-bb7a-b41dab7e3ea8)
- Number of non-empty values in 'filtered_fashion_keywords':
- Examples of original post text:
  1. ğŸ–¤160ä½“åˆ¶å†…é€šå‹¤ç©¿æ­ï½œç§‹å†¬ç©¿ä¸€èº«é«˜çº§ç°é»‘ğŸ©¶ å±‚å±‚å å çš„ç°é»‘è‰²ç³» å¤§è¡£å°±æ˜¯æ°›å›´æ„Ÿæ‹¿æäº†ï½ å–œæ¬¢æœ‰ç‚¹å°ç»†èŠ‚çš„åŒè‰²ç³»ç©¿æ­ . . #ç§‹å†¬ç©¿æ­ #é€šå‹¤ç©¿æ­ #ä½“åˆ¶å†…ç©¿æ­ #ç°è‰²å¤§è¡£ #ç°è‰²å¤§è¡£è¿™ä¹ˆç©¿ #å¤§è¡£ç©¿æ­ #ç¾Šæ¯›å¤§è¡£ #å¥½çœ‹çš„å¤§è¡£ #ç¾Šæ¯›ç¾Šç»’å¤§è¡£ #èŒåœºé€šå‹¤ç©¿æ­ #æˆ‘çš„ä¸Šç­é€šå‹¤ç©¿æ­
  2. ğ•­ğ–‘ğ–†ğ–ˆğ– ğŸˆâ€â¬›â€§â‚ŠËšâ‹†â™¡ #å®å®è¾…é£Ÿ #æ¯æ—¥ç©¿æ­#WEIRDMARKET
  3. Ariseismä½ åˆ«ä¾¿å®œçš„å¤ªç¦»è°±ï¼ï¼ï¼ æ–°å“ä¸Šçº¿å•¦ï½ è¿™æœŸæ–°å“éƒ½å¥½å–œæ¬¢å¥½å–œæ¬¢ï½ è¾£å¦¹é»‘è‰²è¶…çŸ­è£¤ä¹Ÿæœ‰å•¦ï½ #ariseismæˆéƒ½ #ariseism #ARM
- Examples of filtered post text:
  1. blackheartä½“åˆ¶å†…é€šå‹¤ç©¿æ­ç§‹å†¬ç©¿ä¸€èº«é«˜çº§ç°é»‘greyheart å±‚å±‚å å çš„ç°é»‘è‰²ç³» å¤§è¡£å°±æ˜¯æ°›å›´æ„Ÿæ‹¿æäº† å–œæ¬¢æœ‰ç‚¹å°ç»†èŠ‚çš„åŒè‰²ç³»ç©¿æ­ ç§‹å†¬ç©¿æ­ é€šå‹¤ç©¿æ­ ä½“åˆ¶å†…ç©¿æ­ ç°è‰²å¤§è¡£ ç°è‰²å¤§è¡£è¿™ä¹ˆç©¿ å¤§è¡£ç©¿æ­ ç¾Šæ¯›å¤§è¡£ å¥½çœ‹çš„å¤§è¡£ ç¾Šæ¯›ç¾Šç»’å¤§è¡£ èŒåœºé€šå‹¤ç©¿æ­ æˆ‘çš„ä¸Šç­é€šå‹¤ç©¿æ­
  2. ğ•­ğ–‘ğ–†ğ–ˆğ– blackcat å®å®è¾…é£Ÿ æ¯æ—¥ç©¿æ­ weirdmarket
  3. ariseismä½ åˆ«ä¾¿å®œçš„å¤ªç¦»è°± æ–°å“ä¸Šçº¿å•¦ è¿™æœŸæ–°å“éƒ½å¥½å–œæ¬¢å¥½å–œæ¬¢ è¾£å¦¹é»‘è‰²è¶…çŸ­è£¤ä¹Ÿæœ‰å•¦ ariseismæˆéƒ½ ariseism arm

#### Step 1.1 Expand fashion keyword list using RAKE (Rapid Automatic Keyword Extraction)
1. Tokenize the keyword group column to break down fashion phrases into individual words.
2. Apply RAKE to identify high-importance words from the tokenized text.
3. Expand the fashion keyword list by combining tokenized words and extracted keywords.
4. [topics0611_filtered.csv](https://github.com/dengxw66/Multimodal_MKT/blob/diandian_devlop/topics0611_filtered.csv) - 18,793 rows --> [topics_filtered.csv](https://github.com/dengxw66/Multimodal_MKT/blob/diandian_devlop/topics_filtered.csv) - 52,243 rows

#### Step 1.2 Get a non-fashion Chinese corpus
- Chinese Wikipedia Dump
- Use WikiExtractor to convert the XML dump into plain text
- Get extracted_texts
- Filter Non-Fashion Content from the Extracted Texts, using fashion keywords

#### Step 1.3 Prepare Data for Model Training
- Tokenize the Non-Fashion Texts
- Balancing the Dataset: downsample the non-fashion corpus to half the size of the fashion corpus
- Combine with Fashion-Related Tokens
- Shuffling: ensure the model sees both classes during training
- Add class weights to emphasize fashion-related content during training.

#### Step 2 Train the Model
- Split the Data into Training and Validation Sets
- Fine-Tune BERT [fashion_bert_model]()

#### Step 3 Apply the Model
- prepare post data
  - Combine 'post_title' and 'post_content' into 'post_text'
  - Clean 'post_text'
- Use the Trained Model to Classify Fashion-Related Content [post_filtered_bert.csv]()

#### Step 4 Apply Keyword Extraction (RAKE) on Fashion-Related Texts
- Initialize RAKE keyword extractor
- Function to extract fashion-related keywords using RAKE
- Apply RAKE on the fashion_text column to extract keywords 
- Save the final DataFrame with fashion-related keywords to [post_filtered_rake.csv]()

#### Step 5 Apply Soft Matching
- Load the fashion lexicon from 'topics_filtered.csv'
- Load the post_filtered_rake.csv file
- Initialize the BERT tokenizer and model
- Function to get BERT embeddings for a word
- Precompute embeddings for fashion keywords in the lexicon
- Function to compute cosine similarity between two vectors
- Function to filter keywords with soft matching (similarity threshold = .6)
- Apply the fashion keyword filter with soft matching to non-empty 'fashion_keywords' rows
- Apply the filtering function to the 'fashion_keywords' column
- Save the final output with only fashion-related keywords

-------------------------------------------------------------------------------------------------------------------------------------------------
# tfashion1.5 - A model to filter fashion-related words
## Softer Matching - a matching strategy based on cosine similarity using BERT embeddings
- input: topics_filtered.csv (expanded), post_cleaned.csv
- output: post_filtered.csv

### Explanation
- BERT-based Embeddings: We get the word embeddings for each word using BERT.
- Cosine Similarity: For each word in the fashion_keywords column, we calculate the cosine similarity to every word in the fashion lexicon.
- Soft Threshold: If the cosine similarity exceeds the threshold (set to 0.6), we consider the word "fashion-related" and include it in the final list.
- Softer Match: Instead of a hard match (exact word match), this approach allows words that are close in meaning to be considered fashion-related.

### Resuls from soft threshold 0.8
- examples of original post text:
  1. åšè‡ªå·±çš„é»‘ç²‰ å°‘å¥³æ„ŸğŸ¥° è´è¶ç»“å…ƒç´ å¥½å°‘å¥³ã€ç¼é¢é›ªçººè£™å˜å˜å¥½ç©¿#ç²‰é»‘é…è‰² #è¶…çŸ­è£™ #å°‘å¥³æ„Ÿç©¿æ­  #æ³¡æ³¡è¢– #ç²‰è‰²å°‘å¥³å¿ƒ #ç²‰è‰² #è´è¶ç»“ #é»‘ç²‰é…è‰² #åŠèº«è£™,
  2. å¯çˆ±é›ç‹—ç©¿æ­ï½ #å¤§å­¦ç”Ÿ #ç©¿æ­ #å¤å­£çŸ­è¢– #æ˜¥å­£ç©¿æ­ #æ°”è´¨ç©¿æ­ #å°ä¸ªå­ç©¿æ­ #æ—¥å¸¸ç©¿æ­ #ootdæ¯æ—¥ç©¿æ­ #æ¯æ—¥ç©¿æ­,
  3. å›½æ°‘åˆæ‹è£´ç§€æ™ºç‰›ä»”è£¤é…è¡¬è¡«ï¼ŒéŸ©ç³»æ¾å¼›æ„Ÿç» è£´å§ä¸æ„§æ˜¯å—éŸ©å›½æ°‘åˆæ‹ï¼Œæ°”è´¨è¶…ç»ï¼ç¾å¾—æ¯«ä¸è´¹åŠ›ï¼Œç©¿ç€ç®€ç®€å•å•çš„è¡¬è¡«å’Œç‰›ä»”è£¤çœŸçš„å¥½åƒåœ¨æ‹éŸ©å‰§ï¼Œæœ€åå†æ­ä¸ŠæŠ«è‚©å¢åŠ å±‚æ¬¡æ„Ÿï¼Œæ°´æ´—è“å°é¦™é£è®¾è®¡æ„Ÿç‰›ä»”è£¤â•è´¨æ„Ÿå¥½çš„è¡¬è¡«è·Ÿç€è£´ç§€æ™ºç©¿è¿™ç§æ¾å¼›æ„Ÿï¼ŒåŒäº‹è¯´æˆ‘ä¸Šç­ç©¿å¾—åƒå»æ‹éŸ©å‰§#è£´ç§€æ™º#éŸ©ç³»ç©¿æ­ #è¡¬è¡« #æŠ«è‚© #éŸ©å¥³ #missa  #å¥³æ˜æ˜Ÿç©¿æ­ #å¥³æ˜æ˜Ÿç§æœ #ä¸è´¹åŠ›æ°”çš„ç©¿æ­ #ç®€çº¦ç©¿æ­ #å°é¦™é£ç‰›ä»”è£¤ #insåšä¸»ç©¿æ­ #æ¾å¼›æ„Ÿ #è·Ÿç€æ˜æ˜Ÿå­¦ç©¿æ­ #ç‰›ä»”è£¤ #å¤å¤ç‰›ä»”è£¤ #åˆæ‹#æ°”è´¨ç©¿æ­

- examples of filtered post text:
  1. åšè‡ªå·±çš„é»‘ç²‰ å°‘å¥³æ„Ÿsmilingfacewithhearts è´è¶ç»“å…ƒç´ å¥½å°‘å¥³ç¼é¢é›ªçººè£™å˜å˜å¥½ç©¿ ç²‰é»‘é…è‰² è¶…çŸ­è£™ å°‘å¥³æ„Ÿç©¿æ­ æ³¡æ³¡è¢– ç²‰è‰²å°‘å¥³å¿ƒ ç²‰è‰² è´è¶ç»“ é»‘ç²‰é…è‰² åŠèº«è£™']
  2. å¯çˆ±é›ç‹—ç©¿æ­ å¤§å­¦ç”Ÿ ç©¿æ­ å¤å­£çŸ­è¢– æ˜¥å­£ç©¿æ­ æ°”è´¨ç©¿æ­ å°ä¸ªå­ç©¿æ­ æ—¥å¸¸ç©¿æ­ ootdæ¯æ—¥ç©¿æ­ æ¯æ—¥ç©¿æ­ 
  3. []
- Number of empty values in 'filtered_fashion_keywords': 6613
- Number of non-empty values in 'filtered_fashion_keywords': 9009
-------------------------------------------------------------------------------------------------------------------------------------------------

# tfashion1.0 - A model to filter fashion-related words
see [tfashion.ipynb](https://github.com/dengxw66/Multimodal_MKT/blob/diandian_devlop/tfashion.ipynb)
## Step 1. Get a non-fashion Chinese corpus
- Chinese Wikipedia Dump
- Use WikiExtractor to convert the XML dump into plain text
- Get extracted_texts
- Filter Non-Fashion Content from the Extracted Texts, using fashion keywords

## Step 2. Prepare Data for Model Training
- Tokenize the Non-Fashion Texts
- Combine with Fashion-Related Tokens

## Step 3. Train the Model
- Split the Data into Training and Validation Sets
- Fine-Tune BERT

## (Optional) Check data before training
- Check Data Shapes
- Check for Any 'NaN' Values
- Check Data Distribution
- Inspect a Few Examples
- Check Label Value Range
- Verify Dataset Splitting
- Check for Duplicates

## Step 4. Evaluate the Model
 - evaluation resutls:
   
![Screenshot 2024-08-31 at 19 56 45](https://github.com/user-attachments/assets/fb94593b-943a-45f4-b535-7e56b91a3a40)

![Screenshot 2024-08-31 at 19 56 59](https://github.com/user-attachments/assets/debace4e-2335-4118-99c6-5f59dac7947b)

## Step 5. Apply the model
- prepare post data
  - input: [poster_test_fashion_nlpclean.csv](https://github.com/dengxw66/Multimodal_MKT/blob/diandian_devlop/poster_test_fashion_nlpclean.csv)
  - Combine 'post_title' and 'post_content' into 'post_text'
  - Clean and Tokenize 'post_text'
- Filter Non-Fashion Words Using the Model
- output: [post_filtered.csv](https://github.com/dengxw66/Multimodal_MKT/blob/diandian_devlop/post_filtered.csv)

### Results:
- empty values in column fashion_text because the model works in the whole phrase not the individual words.
-------------------------------------------------------------------------------------------------------------------------------------------------

# Clustering based on text

## Use dictionary
see [nlp_dict.ipynb](https://github.com/dengxw66/Multimodal_MKT/blob/diandian_devlop/nlp_dict.ipynb)
### Dictionary 1 - General
##### Input: [topics0611.csv](https://github.com/dengxw66/Multimodal_MKT/blob/diandian_devlop/topics0611.csv), [poster_test_fashion_nlpclean.csv]()
##### Output: [word_suffixes.csv](https://github.com/dengxw66/Multimodal_MKT/blob/diandian_devlop/word_suffixes.csv), keyword_freq_dict1.csv, keyword_freq_by_month_dict1.csv
##### Steps: 
1. Extract common suffixes from the topics0611.csv file.
2. Use those suffixes to search for complete words in the poster_test_fashion_nlpclean.csv file.
3. Do textual data cleaning again.
4. Count overall frequency and by-month frequency.
5. Match images and visualize the popularity by images.

#### Text visualization
<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/14ac29e2-dbe5-4c53-953e-50a6bd1051a2" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/284c782c-b9fc-4c50-921a-28322007ed63" alt="Image 2" width="45%"/>
</div>

#### Image visualization

- Overall Frequency Visualization
<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/4da53b0d-3ab0-4eda-b69e-f2655674237f" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/9dbf8ab9-2d9d-450f-8d87-70aad0a2244a" alt="Image 2" width="45%"/>
</div>
<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/9562d664-52de-4d3b-8fb0-b47b4b8f0f9e" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/d6ec9d5e-9d17-49f4-af20-d0a60ac5b288" alt="Image 2" width="45%"/>
</div>

- By-Month Frequency Visualization

</div>
<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/dcbbe8a9-416e-456c-a9c4-4c3b4c221c9f" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/93da4ca5-a3e0-4b3f-8302-49bde22c4e35" alt="Image 2" width="45%"/>
</div>

<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/021d88bd-edc3-43a2-baff-559db2a71cc7" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/34bff7d0-2413-4e6e-8d68-a0f404180ac3" alt="Image 2" width="45%"/>
</div>
<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/e93fb66e-a033-45c0-8ecc-3cd3364db5b1" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/4065706b-ce34-46c9-9f03-231ce1b0e9e2" alt="Image 2" width="45%"/>
</div>

<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/c43c038c-184b-4d02-b694-8694213a35ca" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/00f49691-201a-4aae-b44d-451bcd720596" alt="Image 2" width="45%"/>
</div>

<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/d434472e-cd24-446a-8735-b3be249e348c" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/9b32dbc2-762d-4850-8c58-6c9aa7a13a0e" alt="Image 2" width="45%"/>
</div>

<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/8099ef99-041b-49d9-a2ee-af2066decd64" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/c6b0ac01-e113-42b5-88d3-c1550941d52b" alt="Image 2" width="45%"/>
</div>
<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/0130a4b9-3f89-4a8c-b942-4e682154907f" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/06fe12c3-edc5-4be0-bdf4-8bde79a8d4e8" alt="Image 2" width="45%"/>
</div>

<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/4e31eaf3-94d4-40bf-9688-91fded50e291" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/891c8aaf-4590-446a-8a2a-2fedc592220c" alt="Image 2" width="45%"/>
</div>
<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/a0f57811-3dc4-42fd-a90b-4452a3df7513" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/b5545b85-abb1-4292-896b-8706853f10c9" alt="Image 2" width="45%"/>
</div>
<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/40235c82-356b-4d96-912e-48e071ca3d26" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/9c274feb-8b17-400d-a0b6-86072e0229c8" alt="Image 2" width="45%"/>
</div>

<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/7b1184a6-413d-4a4c-b25c-0c35f0bf4374" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/f9ad1c08-497d-43a5-9b90-bb1cf55a7292" alt="Image 2" width="45%"/>
</div>
<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/3a50b8c5-2f6f-45d9-b620-3a0846b850b4" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/2066ef33-d687-4a91-ae97-ee5e680e37f1" alt="Image 2" width="45%"/>
</div>

### Dictionary 2 - Specific 
##### Inputs: [topics0611.csv](https://github.com/dengxw66/Multimodal_MKT/blob/diandian_devlop/topics0611.csv), [poster_test_fashion_nlpclean.csv]()
##### Outputs: keyword_freq_dict2.csv, keyword_freq_by_month_dict2.csv
##### Steps:
1. Use topics0611.csv to do exact match with poster_test_fashion_nlpclean.csv.
2. Count overall frequency and by-month frequency.
3. Match images and visualize the popularity by images.

#### Text visualization
<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/dc946c0d-09f3-45f3-91db-e238a193b6df" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/81483025-0f69-4d64-b23a-a211ff5f8969" alt="Image 2" width="45%"/>
</div>

#### Image visualization

- Overall Frequency Visualization
<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/3ee70019-a4d0-485b-9440-bdba111994da" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/7da914b6-4bd3-451d-b1c3-ef1ce46adaf8" alt="Image 2" width="45%"/>
</div>
<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/ace39e68-f010-45e6-98b0-f56a9ee8e20e" alt="Image 1" width="33%"/>
  <img src="https://github.com/user-attachments/assets/7a989d3f-be9b-4c4c-837e-4f0068c1dcd3" alt="Image 2" width="33%"/>
  <img src="https://github.com/user-attachments/assets/8e419642-fb95-456b-a84c-eba465021593" alt="Image 2" width="33%"/>
</div>

- By-Month Frequency Visualization
<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/8ba4c1c6-e9e8-4d22-a9f6-4dd28aac06b3" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/d969cbb0-de30-40e5-b089-583b24b3a631" alt="Image 2" width="45%"/>
</div>
<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/38cbc41f-d621-480e-a0b2-de76d8d9785b" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/c111c75e-95d4-43e9-9a8b-5b9ddc297e3d" alt="Image 2" width="45%"/>
</div>

<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/e8523f35-811b-4348-b19e-50eb35a24b6a" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/20ddb204-221b-47c6-b445-20e07971dfc7" alt="Image 2" width="45%"/>
</div>
<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/d9f0282e-6b59-44db-8e7b-16ad5d0a5599" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/f5b5b9d5-981d-4ef7-b85c-09797b7d38ab" alt="Image 2" width="45%"/>
</div>

<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/8d624106-c8c3-4ebc-b433-919712738b73" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/16d3d0c1-96ac-43b2-a313-4352d12ce3c9" alt="Image 2" width="45%"/>
</div>
<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/790b5e8b-3bed-4ec8-b06a-e518372fb2a2" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/aa2597a8-f574-440e-9e13-87d2cfcea65b" alt="Image 2" width="45%"/>
</div>

<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/ef276976-1195-4aa3-be48-6d6a6d653704" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/13365890-3aef-4923-86db-4078ac849aa2" alt="Image 2" width="45%"/>
</div>
<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/373fe8b8-f0ef-47f0-a6e4-da1a91905b5b" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/339e08d3-f3aa-483d-ba6e-e474be3108cc" alt="Image 2" width="45%"/>
</div>

<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/a0b1f529-da87-4d8d-b984-38cd61534573" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/90552ff2-909b-41f7-b9db-db1211490e84" alt="Image 2" width="45%"/>
</div>
<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/505b4d4a-bd23-4a56-96ca-f7dca1da1c50" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/6f061100-4e6c-4505-b62e-e53f00511bc3" alt="Image 2" width="45%"/>
</div>

<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/c05b6389-35da-4b8e-ae52-affc69f88534" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/f178d7ed-3e26-4434-88c2-6d8aaf61a235" alt="Image 2" width="45%"/>
</div>
<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/de2e855d-da16-4842-9196-c02dbf0b6646" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/8e6c0d2a-4166-43c4-a8a9-a9fb3a632d44" alt="Image 2" width="45%"/>
</div>

## No dictionary
see [nlp_nodict.ipynb](https://github.com/dengxw66/Multimodal_MKT/blob/diandian_devlop/nlp_nodict.ipynb)
##### Inputs: poster_test_fashion_nlpclean.csv
##### Outputs: poster_test_fashion_clustered.csv
##### Steps:
1. Double cleaning on textual data
2. RAKE keyword extraction
3. Use text2vec-large-chinese to generate embedding
4. Use Silhouette Method to find the optimal number of clusters
5. Do KMeans clustering
6. Visualize results

- The best number of clusters based on silhouette score is: 51
- Visualize the popularity of each cluster
<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/e8bf159a-b64c-4d5a-981a-d485ccbaeea9" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/e94f66b3-4c45-4a03-973f-f4f2908d1d31" alt="Image 2" width="45%"/>
</div>

- Visualize the images for top 10 most popular clusters

<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/9deb25e3-d516-4248-ac55-2eb26fdb41bf" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/1b93b66e-fabc-40de-9fa7-f7b233e0cb68" alt="Image 2" width="45%"/>
</div>
<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/1e5b6baa-3d09-4397-8346-24d947a634f6" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/10063b98-bc03-47c9-aa41-7b27f617ffc2" alt="Image 2" width="45%"/>
</div>
<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/692219dd-cf95-4210-9139-2f44aa37049a" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/9002fec1-9862-4014-b41c-64842e70ac10" alt="Image 2" width="45%"/>
</div>
<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/03d88901-8970-46bb-957b-fc7a0b18322c" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/56f143b8-e3fa-4db0-98db-dd5b3d421bb3" alt="Image 2" width="45%"/>
</div>
<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/1f95ed72-81d1-4316-a9a2-1f2e0ca3c9cd" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/03f9157d-0648-4997-90c1-6096cc6916db" alt="Image 2" width="45%"/>
</div>

## No dictionary + Dimensionality reduction
##### Steps:
1. Text Preprocessing
   - Clean and prepare the text data
   - RAKE Keyword Extraction
2. Incorporate S-Bert and UMAP
   - Generate embedding useing SBERT - text2vec-large-chinese
   - Reduce dimensionality using UMAP
   - Find the optimal #clusters using Silhouette Method for
   - Do KMeans clustering
7. Visualize results

##### Findings
- Nice Silhouette score (A reasonable structure is found)
- The best number of clusters based on silhouette score is: 84

<div style="display: flex; justify-content: space-around;">
  <img src="https://github.com/user-attachments/assets/0c2038c8-ef40-48bf-9fed-e38f59b8dcc7" alt="Image 1" width="45%"/>
  <img src="https://github.com/user-attachments/assets/7dec6291-6aa5-4e18-b231-05aeba0ec84b" alt="Image 2" width="45%"/>
</div>


----------------------------------------------------------------------------------------------------------------------------
## Aug 5, 2024
### cloth-segment issues
- need to remove non cloth-focused images (e.g., posts of makeup/accessory/shoes)

### clustering -- find out the optimal number of cluster by silhouette method
![image](https://github.com/user-attachments/assets/caa34e4a-d857-438e-907d-3bf02f3cfddf)
![image](https://github.com/user-attachments/assets/0fd23eb4-f2fa-4b3d-8511-843c56038c94)
![image](https://github.com/user-attachments/assets/d21f3b39-532a-4c5e-896f-a7f5a4b52030)
![image](https://github.com/user-attachments/assets/663344d0-83ea-41a9-8f1e-f83ee1bb09b0)
![image](https://github.com/user-attachments/assets/14dd9560-6947-41eb-9f36-79324ff7eb81)



## July 30, 2024:
####  - added data_prep.ipynb
1. select 200 posters from 50w level posters
2. keep fashion-related posts only

#### - updated data.ipynb
1. visualize special cases of segmentation
2. sentiment analysis on post_comment_content
3. visualize sentiment results
4. add poster's numerical metrics

#### - updated label.ipynb
- visualize proportion and trend

#### - run classification.ipynb and regression.ipynb
- use sample of 300 posters

## Discussion:
1. model architecture: test embedding, vision embedding, numerical embedding --> add audio embedding?
2. heatmap
3. sales data?
4. Bass model
5. Survey? (BrandImageNet mode, LiuLiu 2020)
   
----------------------------------------------
### Video -> Images
1. Extract frames at 1/4, 2/4, and 3/4 of the video's duration
2. Save the extracted frames as images

![Screenshot 2024-07-25 at 13 23 04](https://github.com/user-attachments/assets/78f3144e-1710-4018-a3fc-05a33d8ee2bc)

### Image Segmentation
Original image + the mask -> processed image

![Screenshot 2024-07-25 at 13 23 45](https://github.com/user-attachments/assets/95a27c7e-d74c-43cd-a7f3-25db395a1669)

### Image Segmentation -- special cases
1. mask area too small

<img src="https://github.com/user-attachments/assets/4d276964-1aa6-4be3-a7a7-2c5b9bf5620e" width="450" height="300" />
<img src="https://github.com/user-attachments/assets/d54785c1-f8c7-4974-8e31-2e0e78d152ad" width="450" height="300" />
<img src="https://github.com/user-attachments/assets/a845abda-f0aa-421a-8c86-f127fd8fa929" width="450" height="300" />
<img src="https://github.com/user-attachments/assets/634bcf5b-39d2-44a7-b5da-77d8153c6565" width="450" height="300" />

2. mask area too large

<img src="https://github.com/user-attachments/assets/491c96cb-1920-4490-986f-7537e70d8e76" width="450" height="300" />
<img src="https://github.com/user-attachments/assets/81a9671a-9bdf-4810-9948-7f9fe6a58784" width="450" height="300" />
<img src="https://github.com/user-attachments/assets/a818f392-8e06-4fa4-bd65-4dc1e97630e0" width="450" height="300" />
<img src="https://github.com/user-attachments/assets/abb80344-8286-4206-bb7f-4ef3995ade3f" width="450" height="300" />

### Image Clustering 
- K = 100
- Maybe better to perform image clustering specifically to segment the clothing, rather than focusing on the style or the entire human figure?
- cluster based on pose or style

![Screenshot 2024-07-25 at 13 27 21](https://github.com/user-attachments/assets/854b4f4b-50b3-4d89-b571-20d7aab92bfd)

### Text Preprocessing
1. Removing Stop Words 
2. Tokenization
3. Stemming and Lemmatization
4. Handling Special Characters
5. Translating Emojis
6. replace('1åƒ', '1000').replace('1ä¸‡', '10000â€™) 
7. Sentiment analysis on comments

### Sentiment analysis resutls of first 10 comments

<img src="https://github.com/user-attachments/assets/2f2045f4-e15e-45bc-8747-edf9e29ff3fb" width="450" height="300" />

##### Positive: score > 0.6
##### Negative: score < 0.4
##### Neutral: else

<img src="https://github.com/user-attachments/assets/0e12abbd-9e3a-446c-934a-57b2dfb4ff43" width="300" height="300" />

### Numerical metrics from posters
'ç²‰ä¸æ•°': 'fans_count',
'å…³æ³¨æ•°': 'following_count',
'èµè—æ€»é‡': 'total_likes',
'ç¬”è®°æ•°': 'posts_count'

### Metrics of Popularity

![Screenshot 2024-07-25 at 13 34 15](https://github.com/user-attachments/assets/5064e175-fc7a-4535-8920-fcc059bd65e1)

<img src="https://github.com/user-attachments/assets/cbddfa1a-ef96-4866-b29b-29bfa1d7ac97" width="450" height="300" />

![Screenshot 2024-07-25 at 13 33 59](https://github.com/user-attachments/assets/c4935660-b13f-428b-be33-f883e79c151a)

<img src="https://github.com/user-attachments/assets/d49948a4-16c8-4601-9468-31bd0687514d" width="450" height="300" />


### classification results
Test Accuracy: 60.00%

### regression results
Evaluation Loss: 0.00013176486892131254

