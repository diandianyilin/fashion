{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import umap\n",
    "\n",
    "# Paths\n",
    "embedding_folder = '/data1/dxw_data/llm/redbook_final/script_next/image_embeddings_tag'\n",
    "output_folder = '/data1/dxw_data/llm/redbook_final/script_next/combined_seg_img_pure_094_cluster_imagebind3'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Load concatenated embeddings\n",
    "embedding_files = [os.path.join(embedding_folder, fname) for fname in os.listdir(embedding_folder) if fname.endswith('.pt')]\n",
    "\n",
    "# Load all embeddings into a list\n",
    "all_embeddings = []\n",
    "for embedding_file in tqdm(embedding_files, desc=\"Loading embeddings\"):\n",
    "    embedding = torch.load(embedding_file)\n",
    "    all_embeddings.append(embedding)\n",
    "\n",
    "# Concatenate all embeddings into a single tensor\n",
    "all_embeddings = torch.cat(all_embeddings, dim=0).cpu()  # Move to CPU\n",
    "\n",
    "# Apply UMAP for dimensionality reduction\n",
    "umap_model = umap.UMAP(n_components=2, random_state=0)\n",
    "reduced_embeddings = umap_model.fit_transform(all_embeddings.numpy())\n",
    "\n",
    "# Determine optimal number of clusters using Average Silhouette Method\n",
    "silhouette_scores = []\n",
    "k_values = list(range(2, 501, 5))  # k values from 2 to 500 with a step of 5\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    labels = kmeans.fit_predict(reduced_embeddings)\n",
    "    \n",
    "    if len(set(labels)) > 1:  # Check if we have more than 1 label\n",
    "        score = silhouette_score(reduced_embeddings, labels)\n",
    "        silhouette_scores.append(score)\n",
    "    else:\n",
    "        silhouette_scores.append(-1)  # Append a placeholder score if there's only one label\n",
    "\n",
    "# Plot silhouette scores\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.plot(k_values, silhouette_scores, marker='o')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Average Silhouette Score')\n",
    "plt.title('Average Silhouette Score vs. Number of Clusters')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Select the optimal number of clusters based on the silhouette scores\n",
    "optimal_k = k_values[silhouette_scores.index(max(silhouette_scores))]\n",
    "\n",
    "# Perform clustering with optimal k\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=0)\n",
    "labels = kmeans.fit_predict(reduced_embeddings)\n",
    "\n",
    "# Save clustered images to output folders based on the clustering results\n",
    "for idx, label in tqdm(enumerate(labels), desc=\"Saving clustered images\", total=len(labels)):\n",
    "    label_folder = os.path.join(output_folder, str(label))\n",
    "    os.makedirs(label_folder, exist_ok=True)\n",
    "    \n",
    "    # Extract corresponding image file name from embedding file name\n",
    "    embedding_file = embedding_files[idx]\n",
    "    image_filename = os.path.basename(embedding_file).replace('_embedding.pt', '.png')\n",
    "    \n",
    "    # Define source image path\n",
    "    source_image_path = os.path.join(embedding_folder.replace('combined_embeddings', 'combined_seg_img_pure_094'), image_filename)\n",
    "    \n",
    "    # Copy image to corresponding cluster folder\n",
    "    if os.path.exists(source_image_path):\n",
    "        shutil.copy(source_image_path, os.path.join(label_folder, image_filename))\n",
    "\n",
    "# Save clustering labels to JSON file\n",
    "labels_json = {os.path.basename(embedding_files[idx]): int(label) for idx, label in enumerate(labels)}\n",
    "with open(os.path.join(output_folder, 'labels.json'), 'w') as f:\n",
    "    json.dump(labels_json, f)\n",
    "\n",
    "print(f'Clustering complete. Output saved to {output_folder}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
