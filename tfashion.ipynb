{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been processed and saved to 'nlpclean_processed.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the poster_test_fashion_nlpclean.csv file\n",
    "poster_df = pd.read_csv('/Users/ddyilin/Documents/GitHub/fashion/poster_test_fashion_nlpclean.csv')\n",
    "\n",
    "# Combine the post_title and post_content columns into a new column post_text\n",
    "poster_df['post_text'] = poster_df['post_title'].fillna('') + ' ' + poster_df['post_content'].fillna('')\n",
    "\n",
    "# Keep only the post_text and post_comment_content columns\n",
    "poster_df = poster_df[['post_text', 'post_comment_content']]\n",
    "\n",
    "# Remove duplicate rows\n",
    "poster_df = poster_df.drop_duplicates()\n",
    "\n",
    "# Save the resulting DataFrame to a new CSV file\n",
    "poster_df.to_csv('/Users/ddyilin/Documents/GitHub/fashion/nlpclean_processed.csv', index=False)\n",
    "\n",
    "print(\"Data has been processed and saved to 'nlpclean_processed.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data cleaning and clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/5d/lsfntfvj5jbbj9d1b8z0_qw00000gn/T/jieba.cache\n",
      "Loading model cost 0.314 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning complete. Cleaned data saved to 'nlpclean_processed_cleaned.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "import jieba\n",
    "\n",
    "# Load stopwords from the provided file\n",
    "with open('/Users/ddyilin/Documents/GitHub/fashion/stopwords_cn.txt', 'r', encoding='utf-8') as f:\n",
    "    stopwords = set(f.read().splitlines())\n",
    "\n",
    "# Load the nlpclean_processed.csv file\n",
    "poster_df = pd.read_csv('/Users/ddyilin/Documents/GitHub/fashion/nlpclean_processed.csv')\n",
    "\n",
    "# Function for text cleaning\n",
    "def clean_text(text, stopwords):\n",
    "    # Convert emojis to text\n",
    "    text = emoji.demojize(text)\n",
    "    \n",
    "    # Remove specific patterns\n",
    "    text = re.sub(r'- 小红书,,', '', text)\n",
    "    text = re.sub(r',,\\d{2}-\\d{2},,', '', text)\n",
    "    text = re.sub(r'#', ' ', text)\n",
    "    \n",
    "    # Remove digits\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove special characters\n",
    "    cleaned_text = ''.join(char for char in text if char.isalnum() or char.isspace())\n",
    "    \n",
    "    # Tokenize\n",
    "    words = jieba.cut(cleaned_text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    filtered_words = [word for word in words if word not in stopwords]\n",
    "    \n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Apply data cleaning to post_text and post_comment_content\n",
    "poster_df['post_text_clean'] = poster_df['post_text'].apply(lambda x: clean_text(x, stopwords))\n",
    "poster_df['post_comment_content_clean'] = poster_df['post_comment_content'].apply(lambda x: clean_text(str(x), stopwords))\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "poster_df.to_csv('/Users/ddyilin/Documents/GitHub/fashion/nlpclean_processed_cleaned.csv', index=False)\n",
    "\n",
    "print(\"Data cleaning complete. Cleaned data saved to 'nlpclean_processed_cleaned.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
