{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic TF-IDF and K-means clustering\n",
    " - Step 1: Preprocess the Text\n",
    " - Step 2: Apply K-means Clustering\n",
    " - Step 3: Evaluate and Visualize the Clusters\n",
    " - Step 4: Save the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "- TF-IDF Vectorization: Converts the fashion_text into a numerical form.\n",
    "- K-means Clustering: Groups similar texts together.\n",
    "- PCA Visualization: Optionally visualizes the clusters in 2D space.\n",
    "- Saving Results: Saves the DataFrame with the cluster assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('/home/disk1/red_disk1/Multimodal_MKT/post_filtered.csv')\n",
    "\n",
    "# Convert the 'fashion_text' column into TF-IDF vectors\n",
    "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "X = vectorizer.fit_transform(df['fashion_text'].dropna())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Define the number of clusters\n",
    "num_clusters = 5  # You can adjust this based on your needs\n",
    "\n",
    "# Apply K-means clustering\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reduce the dimensionality for visualization\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X.toarray())\n",
    "\n",
    "# Plot the clusters\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=df['cluster'], cmap='viridis')\n",
    "plt.title('Clusters of Fashion-Related Texts')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame with cluster labels\n",
    "df.to_csv('/home/disk1/red_disk1/Multimodal_MKT/post_filtered_with_clusters0.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced clustering\n",
    "- Step 1: Extract Keywords with RAKE\n",
    "- Step 2: Generate Embeddings with SBERT\n",
    "- Step 3: Apply UMAP for Dimensionality Reduction\n",
    "- Step 4: Apply Clustering (K-means or HDBSCAN)\n",
    "- Step 5: Visualize the Clusters\n",
    "- Step 6: Save the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "- RAKE helps in focusing on important keywords.\n",
    "- SBERT captures the semantic meaning of the text.\n",
    "- UMAP reduces the dimensionality for better visualization and clustering.\n",
    "- HDBSCAN can find clusters of varying densities, which can be more effective than K-means in some cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rake_nltk import Rake\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('/home/disk1/red_disk1/Multimodal_MKT/post_filtered.csv')\n",
    "\n",
    "# Initialize RAKE\n",
    "rake = Rake()\n",
    "\n",
    "# Extract keywords for each text\n",
    "df['keywords'] = df['fashion_text'].apply(lambda x: ' '.join(rake.extract_keywords_from_text(x) or ['']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the pre-trained SBERT model\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# Generate embeddings for the text\n",
    "df['embeddings'] = df['fashion_text'].apply(lambda x: model.encode(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "# Convert the list of embeddings to a matrix\n",
    "embeddings_matrix = list(df['embeddings'])\n",
    "\n",
    "# Reduce dimensionality with UMAP\n",
    "umap_model = umap.UMAP(n_neighbors=15, n_components=2, metric='cosine')\n",
    "reduced_embeddings = umap_model.fit_transform(embeddings_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Apply K-means clustering\n",
    "num_clusters = 5\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(reduced_embeddings)\n",
    "\n",
    "# Optionally, you could use HDBSCAN\n",
    "import hdbscan\n",
    "\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=10, metric='euclidean', cluster_selection_method='eom')\n",
    "df['cluster'] = clusterer.fit_predict(reduced_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], c=df['cluster'], cmap='viridis')\n",
    "plt.title('Clusters of Fashion-Related Texts')\n",
    "plt.xlabel('UMAP Component 1')\n",
    "plt.ylabel('UMAP Component 2')\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame with cluster labels\n",
    "df.to_csv('/home/disk1/red_disk1/Multimodal_MKT/post_filtered_with_clusters.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
